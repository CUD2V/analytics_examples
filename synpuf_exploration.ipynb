{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to hide useless errors if using OAuth with BigQuery\n",
    "import logging\n",
    "logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.CRITICAL)\n",
    "# don't want to be messaged about future warnings as I'm not explicitly calling code that is being warned about\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# set this to either postgres or bigquery ####\n",
    "datasource = 'bigquery'\n",
    "##############################################\n",
    "\n",
    "if datasource == 'postgres':\n",
    "    # get connected to the database\n",
    "    connection = pg.connect(\"host=localhost dbname=ohdsi user=ohdsi password=ohdsi\")\n",
    "\n",
    "    # print the connection string we will use to connect\n",
    "    print(\"Connecting to database: \", connection)\n",
    "\n",
    "    # conn.cursor will return a cursor object, you can use this cursor to perform queries\n",
    "    cursor = connection.cursor()\n",
    "    print(\"Connected to Postgres database!\\n\")\n",
    "elif datasource == 'bigquery':\n",
    "    connection = {\n",
    "        'project_id' : 'synpuf-omop-project',\n",
    "        'dialect'    : 'standard'\n",
    "    }\n",
    "    print(\"Setup Google BigQuery connection\")\n",
    "else:\n",
    "    connection = None\n",
    "\n",
    "def read_data(sql):\n",
    "    if datasource == 'postgres':\n",
    "        return pandas.read_sql(sql, connection)\n",
    "    elif datasource == 'bigquery':\n",
    "        return pandas.read_gbq(sql, **connection)\n",
    "    else:\n",
    "        return pandas.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_These next cells are charts looking at births by year - of the population still active in medicare today._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.charts import Bar\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.charts import defaults\n",
    "defaults.width = 900\n",
    "defaults.height = 700\n",
    "\n",
    "age_df = read_data('''\n",
    "select\n",
    "    count(year_of_birth) count,\n",
    "    year_of_birth,\n",
    "    c1.concept_name gender\n",
    "from synpuf_omop.person p\n",
    "left join synpuf_omop.concept c1 on p.gender_concept_id = c1.concept_id\n",
    "group by gender, year_of_birth\n",
    "order by year_of_birth, gender\n",
    "''')\n",
    "\n",
    "p = Bar(age_df,             # source of data\n",
    "        'year_of_birth',    # columns from dataframe to use\n",
    "        #label='origin', \n",
    "        agg='sum',\n",
    "        values='count',\n",
    "        stack='gender',\n",
    "        title=\"Births by year, stacked by gender\",\n",
    "        legend='top_right')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.charts import Bar\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.charts import defaults\n",
    "defaults.width = 900\n",
    "defaults.height = 700\n",
    "\n",
    "pct_df = read_data(\n",
    "'''\n",
    "select\n",
    "    year_of_birth,\n",
    "    count(case when c1.concept_name = 'FEMALE' then 1 end) gender_count,\n",
    "    'FEMALE' gender,\n",
    "    count(1) total_births\n",
    "from synpuf_omop.person p\n",
    "left join synpuf_omop.concept c1 on p.gender_concept_id = c1.concept_id\n",
    "group by year_of_birth\n",
    "union all\n",
    "select\n",
    "    year_of_birth,\n",
    "    count(case when c1.concept_name = 'MALE' then 1 end) gender_count,\n",
    "    'MALE' gender,\n",
    "    count(1) total_births\n",
    "from synpuf_omop.person p\n",
    "left join synpuf_omop.concept c1 on p.gender_concept_id = c1.concept_id\n",
    "group by year_of_birth\n",
    "order by year_of_birth, gender asc\n",
    "''')\n",
    "\n",
    "def f(i):\n",
    "    return float(i['gender_count']) / float(i['total_births'])\n",
    "pct_df['pct'] = pct_df.apply(f, axis=1)\n",
    "\n",
    "\n",
    "p = Bar(pct_df,             # source of data\n",
    "        values='pct',          # y axis\n",
    "        label='year_of_birth', # x axis \n",
    "        agg='sum',\n",
    "        stack='gender',\n",
    "        title=\"Percentage of births by year, stacked by gender\",\n",
    "        legend='top_right')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_These next few cells look at drug duration (how long a perscription is to last)_\n",
    "\n",
    "Due to differences in SQL dialects, this is the PostgreSQL version - inline below is the Google BigQuery version. Might be possible to make one statement work for both...\n",
    "\n",
    "```sql\n",
    "select\n",
    "    --person_id,\n",
    "    --drug_concept_id,\n",
    "    c1.concept_name drug_name,\n",
    "    --drug_era_start_date,\n",
    "    --drug_era_end_date,\n",
    "    drug_era_end_date - drug_era_start_date duration\n",
    "from synpuf_omop.drug_era d\n",
    "left join synpuf_omop.concept c1 on d.drug_concept_id = c1.concept_id\n",
    "where c1.concept_name in (\n",
    "select drug_name from (\n",
    "    select\n",
    "    c1.concept_name drug_name,\n",
    "    count(1) count\n",
    "    from synpuf_omop.drug_era d\n",
    "    left join synpuf_omop.concept c1 on d.drug_concept_id = c1.concept_id\n",
    "    group by drug_name\n",
    "    order by count desc\n",
    "    limit 25\n",
    "   ) x\n",
    ")\n",
    "order by drug_name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps modify this query to look at drugs with most variation in duration?\n",
    "\n",
    "from bokeh.charts import BoxPlot, output_file, show\n",
    "from bokeh.sampledata.autompg import autompg as df\n",
    "from bokeh.charts import defaults\n",
    "defaults.width = 900\n",
    "defaults.height = 900\n",
    "\n",
    "dd_df = read_data(\n",
    "'''\n",
    "select\n",
    "    --person_id,\n",
    "    --drug_concept_id,\n",
    "    c1.concept_name drug_name,\n",
    "    --drug_era_start_date,\n",
    "    --drug_era_end_date,\n",
    "    date_diff(cast(drug_era_end_date as date), cast(drug_era_start_date as date), day) as duration\n",
    "from synpuf_omop.drug_era d\n",
    "left join synpuf_omop.concept c1 on d.drug_concept_id = c1.concept_id\n",
    "where c1.concept_name in (\n",
    "select drug_name from (\n",
    "    select\n",
    "    c1.concept_name drug_name,\n",
    "    count(1) count\n",
    "    from synpuf_omop.drug_era d\n",
    "    left join synpuf_omop.concept c1 on d.drug_concept_id = c1.concept_id\n",
    "    group by drug_name\n",
    "    order by count desc\n",
    "    limit 25\n",
    "   ) x\n",
    ")\n",
    "order by drug_name\n",
    "''')\n",
    "\n",
    "p = BoxPlot(dd_df,\n",
    "            values='duration',      # y axis\n",
    "            label='drug_name',      # x axis\n",
    "            title=\"Drug Duration Box Plot\",\n",
    "            legend=False,\n",
    "           )\n",
    "p.xaxis.axis_label = \"Drug\"\n",
    "p.yaxis.axis_label = \"Duration (days)\"\n",
    "\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Alternatively, you can just get all the data via more simple SQL SELECT statment and do the data processing via Pandas_\n",
    "\n",
    "Again as with the previous query, due to SQL dialect differences, this is the PostgreSQL version - in cell below is the BigQuery version:\n",
    "\n",
    "```sql\n",
    "select\n",
    "    c1.concept_name drug_name,\n",
    "    drug_era_end_date - drug_era_start_date duration\n",
    "from synpuf_omop.drug_era d\n",
    "left join synpuf_omop.concept c1 on d.drug_concept_id = c1.concept_id\n",
    "order by drug_name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_df = None\n",
    "drug_df = None\n",
    "top_25 = None\n",
    "top_drugs = None\n",
    "\n",
    "drug_df = read_data(\n",
    "'''\n",
    "select\n",
    "    c1.concept_name drug_name,\n",
    "    date_diff(cast(drug_era_end_date as date), cast(drug_era_start_date as date), day) as duration\n",
    "from synpuf_omop.drug_era d\n",
    "left join synpuf_omop.concept c1 on d.drug_concept_id = c1.concept_id\n",
    "order by drug_name\n",
    "''')\n",
    "\n",
    "# if we only want to look at 25 most common drugs\n",
    "# count rows grouping by drug_name\n",
    "size_df = drug_df.groupby(\"drug_name\").size()\n",
    "# sort the counted result and only return top 25\n",
    "top_25 = size_df.sort_values(ascending = False).head(25)\n",
    "# for verification purposes show all rows from original dataset matching most common drug\n",
    "#drug_df[drug_df.drug_name.str.contains(top_25.index[0]) == True]\n",
    "# only keep rows that match the top_25 pandas series (single column of a dataframe)\n",
    "top_drugs = drug_df[drug_df['drug_name'].isin(top_25.index)]\n",
    "# for verification sql method says there are 1683795 rows\n",
    "print(\"Does Pandas version match SQL results:\", top_drugs.shape[0] == 1683795)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.charts import BoxPlot, output_file, show\n",
    "from bokeh.sampledata.autompg import autompg as df\n",
    "from bokeh.charts import defaults\n",
    "defaults.width = 900\n",
    "defaults.height = 900\n",
    "p = BoxPlot(top_drugs,\n",
    "            values='duration',      # y axis\n",
    "            label='drug_name',      # x axis\n",
    "            title=\"Drug Duration Box Plot\",\n",
    "            legend=False,\n",
    "           )\n",
    "p.xaxis.axis_label = \"Drug\"\n",
    "p.yaxis.axis_label = \"Duration (days)\"\n",
    "\n",
    "\n",
    "show(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort identification\n",
    "\n",
    "Suppose we want to do some analysis including prediction for patients that complain of lower back pain (SNOMED code 279039007 - see http://bioportal.bioontology.org/ontologies/SNOMEDCT?p=classes&conceptid=279039007 or https://phinvads.cdc.gov/vads/http:/phinvads.cdc.gov/vads/ViewCodeSystemConcept.action?oid=2.16.840.1.113883.6.96&code=279039007 for more information)\n",
    "\n",
    "The OMOP data model has [CONDITION_OCCURRENCE](http://www.ohdsi.org/web/wiki/doku.php?id=documentation:cdm:condition_occurrence) table to document findings. The [CONDITION_ERA](http://www.ohdsi.org/web/wiki/doku.php?id=documentation:cdm:condition_era) table is a calculation of a condition duration.\n",
    "\n",
    "While there are many elements that we could use for predicting condition duration, suppose we start with basic demographic information about the patient. Here's a query that creates a pandas dataframe with our desired cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backpain_df = read_data(\n",
    "'''\n",
    "SELECT\n",
    "  c.person_id,\n",
    "  gender_concept_id,\n",
    "  year_of_birth,\n",
    "  race_concept_id,\n",
    "  ethnicity_concept_id,\n",
    "  location_id,\n",
    "  DATE_DIFF(CAST(condition_era_end_date AS date), CAST(condition_era_start_date AS date), day) AS duration\n",
    "FROM\n",
    "  synpuf_omop.condition_era c\n",
    "LEFT JOIN\n",
    "  synpuf_omop.person p\n",
    "ON\n",
    "  c.person_id = p.person_id\n",
    "WHERE\n",
    "  condition_concept_id = 194133\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary information about dataset\n",
    "print(backpain_df.describe().to_string())\n",
    "\n",
    "# prevent wrapping when printing the full dataframe\n",
    "pandas.set_option('display.expand_frame_repr', False)\n",
    "print(backpain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf = backpain_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the data in this dataset is categorical, so need to use dummy encoding on each categorical column\n",
    "# so that regression will work correctly. Here's the categorical columns:\n",
    "#   gender_concept_id     (binary)\n",
    "#   race_concept_id       (multiple categories)\n",
    "#   ethnicity_concept_id  (binary)\n",
    "#   location_id           (multiple categories)\n",
    "#\n",
    "# can't do them all at once - so step through one at a time\n",
    "bf = pandas.get_dummies(bf, columns=['gender_concept_id'], drop_first=True)\n",
    "bf = pandas.get_dummies(bf, columns=['race_concept_id'], drop_first=True)\n",
    "bf = pandas.get_dummies(bf, columns=['ethnicity_concept_id'], drop_first=True)\n",
    "bf = pandas.get_dummies(bf, columns=['location_id'], drop_first=True)\n",
    "print(bf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only run this cell if previous results look correct\n",
    "backpain_df = bf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(backpain_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into independent and dependent variables\n",
    "\n",
    "# exclude person_id and duration from independent variables\n",
    "input_df = backpain_df.drop(['person_id', 'duration'], axis=1)\n",
    "\n",
    "output_df = backpain_df['duration']\n",
    "\n",
    "# split data into training vs testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_train, input_test, output_train, output_test = train_test_split(input_df, output_df, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now generate linear regression model on training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(input_train, output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print intercept and coefficients\n",
    "print(\"Intercept: \", lm.intercept_)\n",
    "print(\"Coefficients: \", lm.coef_)\n",
    "print(\"R^2 value: \", lm.score(input_train, output_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate model on test data\n",
    "\n",
    "# now predict answers (regression) - since we only care about whole days, round all output to whole numbers\n",
    "output_pred = pandas.Series(data=lm.predict(input_test))\n",
    "output_pred = output_pred.round()\n",
    "\n",
    "for index, value in output_pred.iteritems():\n",
    "    print('Real value: ', output_test.values[index], 'Predicted value: ', value)\n",
    "    if index >= 10:\n",
    "        break\n",
    "        \n",
    "# should next calculate various measures such as precision, recall, etc. \n",
    "# See https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case\n",
    "# for some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final notes\n",
    "\n",
    "In order to decide which variables are meaningful in the model, methods such as back-propigation, forward-propigation or similar methods should be used.\n",
    "\n",
    "Additionally, other regression methods may work better for predicting duration - in fact the data may not even be suited for Linear Regression. In order for Linear Regression to work, certain assumptions about the data must be true. For more information see: http://pareonline.net/getvn.asp?n=2&v=8\n",
    "\n",
    "Also, since this data set has other elements, the inclusion of other factors may help in predicting condition duration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
